textbook:
  'Dynamic Programming and Stochastic Control: A Comprehensive Guide":':
    chapters:
    - '- Chapter 1: Finite Horizon Problems:':
        sections:
        - '- Section: 1.1 Bellman Equation:':
            subsections:
            - 1.1a Introduction to Bellman Equation
            - 1.1b Applications of Bellman Equation
            - 1.1c Solving Bellman Equation
        - '- Section: 1.2 Hamilton-Jacobi-Bellman Equation:':
            subsections:
            - 1.2a Definition of Hamilton-Jacobi-Bellman Equation
            - 1.2b Solving Hamilton-Jacobi-Bellman Equation
            - 1.2c Applications of Hamilton-Jacobi-Bellman Equation
        - '- Section: 1.3 Backward Induction:':
            subsections:
            - 1.3a Introduction to Backward Induction
            - 1.3b Backward Induction in Decision Making
            - 1.3c Backward Induction in Game Theory
        - '- Section: 1.4 Value Iteration:':
            subsections:
            - 1.4a Introduction to Value Iteration
            - 1.4b Value Iteration Algorithm
            - 1.4c Convergence of Value Iteration
    - '- Chapter 2: Simple Infinite Horizon Problems:':
        sections:
        - '- Section: 2.1 Discounted Cost:':
            subsections:
            - 2.1a Definition of Discounted Cost
            - 2.1b Calculating Discounted Cost
            - 2.1c Applications of Discounted Cost
        - '- Section: 2.2 Average Cost:':
            subsections:
            - 2.2a Definition of Average Cost
            - 2.2b Calculating Average Cost
            - 2.2c Applications of Average Cost
        - '- Section: 2.3 Infinite Horizon Value Iteration:':
            subsections:
            - 2.3a Introduction to Infinite Horizon Value Iteration
            - 2.3b Infinite Horizon Value Iteration Algorithm
            - 2.3c Convergence of Infinite Horizon Value Iteration
        - '- Section: 2.4 Infinite Horizon Policy Iteration:':
            subsections:
            - 2.4a Introduction to Infinite Horizon Policy Iteration
            - 2.4b Infinite Horizon Policy Iteration Algorithm
            - 2.4c Convergence of Infinite Horizon Policy Iteration
    - '- Chapter 3: Advanced Infinite Horizon Problems:':
        sections:
        - '- Section: 3.1 Markov Decision Processes:':
            subsections:
            - 3.1a Introduction to Markov Decision Processes
            - 3.1b Solving Markov Decision Processes
            - 3.1c Applications of Markov Decision Processes
        - '- Section: 3.2 Stochastic Shortest Path:':
            subsections:
            - 3.2a Definition of Stochastic Shortest Path
            - 3.2b Solving Stochastic Shortest Path Problems
            - 3.2c Applications of Stochastic Shortest Path
        - '- Section: 3.3 Average Reward Reinforcement Learning:':
            subsections:
            - 3.3a Introduction to Average Reward Reinforcement Learning
            - 3.3b Average Reward Reinforcement Learning Algorithm
            - 3.3c Applications of Average Reward Reinforcement Learning
        - '- Section: 3.4 Policy Gradient Methods:':
            subsections:
            - 3.4a Introduction to Policy Gradient Methods
            - 3.4b Policy Gradient Algorithms
            - 3.4c Applications of Policy Gradient Methods
    - '- Chapter 4: Approximate Dynamic Programming:':
        sections:
        - '- Section: 4.1 Value Function Approximation:':
            subsections:
            - 4.1a Introduction to Value Function Approximation
            - 4.1b Value Function Approximation Techniques
            - 4.1c Applications of Value Function Approximation
        - '- Section: 4.2 Policy Function Approximation:':
            subsections:
            - 4.2a Introduction to Policy Function Approximation
            - 4.2b Policy Function Approximation Techniques
            - 4.2c Applications of Policy Function Approximation
        - '- Section: 4.3 Model-Based Approximate Dynamic Programming:':
            subsections:
            - 4.3a Introduction to Model-Based Approximate Dynamic Programming
            - 4.3b Model-Based Approximate Dynamic Programming Techniques
            - 4.3c Applications of Model-Based Approximate Dynamic Programming
        - '- Section: 4.4 Model-Free Approximate Dynamic Programming:':
            subsections:
            - 4.4a Introduction to Model-Free Approximate Dynamic Programming
            - 4.4b Model-Free Approximate Dynamic Programming Techniques
            - 4.4c Applications of Model-Free Approximate Dynamic Programming
    - '- Chapter 5: Optimal Control in Continuous Time:':
        sections:
        - '- Section: 5.1 Hamilton-Jacobi-Bellman Equation:':
            subsections:
            - 5.1a Introduction to Hamilton-Jacobi-Bellman Equation
            - 5.1b Solving Hamilton-Jacobi-Bellman Equation
            - 5.1c Applications of Hamilton-Jacobi-Bellman Equation
        - '- Section: 5.2 Pontryagin''s Minimum Principle:':
            subsections:
            - 5.2a Introduction to Pontryagin's Minimum Principle
            - 5.2b Applying Pontryagin's Minimum Principle
            - 5.2c Applications of Pontryagin's Minimum Principle
        - '- Section: 5.3 Existence and Uniqueness of Optimal Control:':
            subsections:
            - 5.3a Introduction to Existence and Uniqueness of Optimal Control
            - 5.3b Proving Existence and Uniqueness of Optimal Control
            - 5.3c Applications of Existence and Uniqueness of Optimal Control
        - '- Section: 5.4 Linear Quadratic Regulator in Continuous Time:':
            subsections:
            - 5.4a Introduction to Linear Quadratic Regulator in Continuous Time
            - 5.4b Solving Linear Quadratic Regulator in Continuous Time
            - 5.4c Applications of Linear Quadratic Regulator in Continuous Time
    - '- Chapter 6: Reinforcement Learning:':
        sections:
        - '- Section: 6.1 Temporal Difference Learning:':
            subsections:
            - 6.1a Introduction to Temporal Difference Learning
            - 6.1b Temporal Difference Learning Algorithm
            - 6.1c Applications of Temporal Difference Learning
        - '- Section: 6.2 Q-Learning:':
            subsections:
            - 6.2a Introduction to Q-Learning
            - 6.2b Q-Learning Algorithm
            - 6.2c Applications of Q-Learning
        - '- Section: 6.3 Value Function Approximation:':
            subsections:
            - 6.3a Introduction to Value Function Approximation
            - 6.3b Value Function Approximation Techniques
            - 6.3c Applications of Value Function Approximation
        - '- Section: 6.4 Policy Gradient Methods:':
            subsections:
            - 6.4a Introduction to Policy Gradient Methods
            - 6.4b Policy Gradient Algorithms
            - 6.4c Applications of Policy Gradient Methods
    - '- Chapter 7: Multi-Agent Reinforcement Learning:':
        sections:
        - '- Section: 7.1 Markov Games:':
            subsections:
            - 7.1a Introduction to Markov Games
            - 7.1b Solving Markov Games
            - 7.1c Applications of Markov Games
        - '- Section: 7.2 Nash Equilibrium:':
            subsections:
            - 7.2a Definition of Nash Equilibrium
            - 7.2b Finding Nash Equilibrium
            - 7.2c Applications of Nash Equilibrium
        - '- Section: 7.3 Joint Action Learning:':
            subsections:
            - 7.3a Introduction to Joint Action Learning
            - 7.3b Joint Action Learning Techniques
            - 7.3c Applications of Joint Action Learning
        - '- Section: 7.4 Decentralized Learning:':
            subsections:
            - 7.4a Introduction to Decentralized Learning
            - 7.4b Decentralized Learning Techniques
            - 7.4c Applications of Decentralized Learning
    - '- Chapter 8: Approximate Dynamic Programming:':
        sections:
        - '- Section: 8.1 Value Function Approximation:':
            subsections:
            - 8.1a Introduction to Value Function Approximation
            - 8.1b Value Function Approximation Techniques
            - 8.1c Applications of Value Function Approximation
        - '- Section: 8.2 Policy Function Approximation:':
            subsections:
            - 8.2a Introduction to Policy Function Approximation
            - 8.2b Policy Function Approximation Techniques
            - 8.2c Applications of Policy Function Approximation
        - '- Section: 8.3 Model-Based Approximate Dynamic Programming:':
            subsections:
            - 8.3a Introduction to Model-Based Approximate Dynamic Programming
            - 8.3b Model-Based Approximate Dynamic Programming Techniques
            - 8.3c Applications of Model-Based Approximate Dynamic Programming
        - '- Section: 8.4 Model-Free Approximate Dynamic Programming:':
            subsections:
            - 8.4a Introduction to Model-Free Approximate Dynamic Programming
            - 8.4b Model-Free Approximate Dynamic Programming Techniques
            - 8.4c Applications of Model-Free Approximate Dynamic Programming
    - '- Chapter 9: Reinforcement Learning in Robotics:':
        sections:
        - '- Section: 9.1 Sensor-Based Control:':
            subsections:
            - 9.1a Introduction to Sensor-Based Control
            - 9.1b Sensor-Based Control Techniques
            - 9.1c Applications of Sensor-Based Control
        - '- Section: 9.2 Model-Free Control:':
            subsections:
            - 9.2a Introduction to Model-Free Control
            - 9.2b Model-Free Control Techniques
            - 9.2c Applications of Model-Free Control
        - '- Section: 9.3 Model-Based Control:':
            subsections:
            - 9.3a Introduction to Model-Based Control
            - 9.3b Model-Based Control Techniques
            - 9.3c Applications of Model-Based Control
        - '- Section: 9.4 Exploration and Exploitation:':
            subsections:
            - 9.4a Introduction to Exploration and Exploitation
            - 9.4b Balancing Exploration and Exploitation
            - 9.4c Applications of Exploration and Exploitation
    - '- Chapter 10: Applications of Dynamic Programming:':
        sections:
        - '- Section: 10.1 Optimal Control of Queues:':
            subsections:
            - 10.1a Introduction to Optimal Control of Queues
            - 10.1b Optimal Control of Queues Techniques
            - 10.1c Applications of Optimal Control of Queues
        - '- Section: 10.2 Inventory Control:':
            subsections:
            - 10.2a Introduction to Inventory Control
            - 10.2b Inventory Control Techniques
            - 10.2c Applications of Inventory Control
        - '- Section: 10.3 Portfolio Optimization:':
            subsections:
            - 10.3a Introduction to Portfolio Optimization
            - 10.3b Portfolio Optimization Techniques
            - 10.3c Applications of Portfolio Optimization
        - '- Section: 10.4 Resource Allocation:':
            subsections:
            - 10.4a Introduction to Resource Allocation
            - 10.4b Resource Allocation Techniques
            - 10.4c Applications of Resource Allocation
    - '- Chapter 11: Routing and Scheduling Problems:':
        sections:
        - '- Section: 11.1 Introduction to Routing and Scheduling Problems:':
            subsections:
            - 11.1a Definition of Routing and Scheduling Problems
            - 11.1b Solving Routing and Scheduling Problems
            - 11.1c Applications of Routing and Scheduling Problems
        - '- Section: 11.2 Optimal Stopping Problems:':
            subsections:
            - 11.2a Introduction to Optimal Stopping Problems
            - 11.2b Solving Optimal Stopping Problems
            - 11.2c Applications of Optimal Stopping Problems
        - '- Section: 11.3 Advanced Routing and Scheduling Problems:':
            subsections:
            - 11.3a Introduction to Advanced Routing and Scheduling Problems
            - 11.3b Solving Advanced Routing and Scheduling Problems
            - 11.3c Applications of Advanced Routing and Scheduling Problems
        - '- Section: 11.4 Advanced Optimal Stopping Problems:':
            subsections:
            - 11.4a Introduction to Advanced Optimal Stopping Problems
            - 11.4b Solving Advanced Optimal Stopping Problems
            - 11.4c Applications of Advanced Optimal Stopping Problems
    - '- Chapter 12: Advanced Reinforcement Learning:':
        sections:
        - '- Section: 12.1 Deep Reinforcement Learning:':
            subsections:
            - 12.1a Introduction to Deep Reinforcement Learning
            - 12.1b Deep Reinforcement Learning Techniques
            - 12.1c Applications of Deep Reinforcement Learning
        - '- Section: 12.2 Model-Based Reinforcement Learning:':
            subsections:
            - 12.2a Introduction to Model-Based Reinforcement Learning
            - 12.2b Model-Based Reinforcement Learning Techniques
            - 12.2c Applications of Model-Based Reinforcement Learning
        - '- Section: 12.3 Advanced Multi-Agent Reinforcement Learning:':
            subsections:
            - 12.3a Introduction to Advanced Multi-Agent Reinforcement Learning
            - 12.3b Advanced Multi-Agent Reinforcement Learning Techniques
            - 12.3c Applications of Advanced Multi-Agent Reinforcement Learning
        - '- Section: 12.4 Advanced Approximate Dynamic Programming:':
            subsections:
            - 12.4a Introduction to Advanced Approximate Dynamic Programming
            - 12.4b Advanced Approximate Dynamic Programming Techniques
            - 12.4c Applications of Advanced Approximate Dynamic Programming
    - '- Chapter 13: Advanced Optimal Control in Continuous Time:':
        sections:
        - '- Section: 13.1 Advanced Hamilton-Jacobi-Bellman Equation:':
            subsections:
            - 13.1a Introduction to Advanced Hamilton-Jacobi-Bellman Equation
            - 13.1b Solving Advanced Hamilton-Jacobi-Bellman Equation
            - 13.1c Applications of Advanced Hamilton-Jacobi-Bellman Equation
        - '- Section: 13.2 Advanced Pontryagin''s Minimum Principle:':
            subsections:
            - 13.2a Introduction to Advanced Pontryagin's Minimum Principle
            - 13.2b Applying Advanced Pontryagin's Minimum Principle
            - 13.2c Applications of Advanced Pontryagin's Minimum Principle
        - '- Section: 13.3 Advanced Existence and Uniqueness of Optimal Control:':
            subsections:
            - 13.3a Introduction to Advanced Existence and Uniqueness of Optimal Control
            - 13.3b Proving Advanced Existence and Uniqueness of Optimal Control
            - 13.3c Applications of Advanced Existence and Uniqueness of Optimal Control
        - '- Section: 13.4 Advanced Linear Quadratic Regulator in Continuous Time:':
            subsections:
            - 13.4a Introduction to Advanced Linear Quadratic Regulator in Continuous
              Time
            - 13.4b Solving Advanced Linear Quadratic Regulator in Continuous Time
            - 13.4c Applications of Advanced Linear Quadratic Regulator in Continuous
              Time
    - '- Chapter 14: Advanced Reinforcement Learning in Robotics:':
        sections:
        - '- Section: 14.1 Advanced Sensor-Based Control:':
            subsections:
            - 14.1a Introduction to Advanced Sensor-Based Control
            - 14.1b Advanced Sensor-Based Control Techniques
            - 14.1c Applications of Advanced Sensor-Based Control
        - '- Section: 14.2 Advanced Model-Free Control:':
            subsections:
            - 14.2a Introduction to Advanced Model-Free Control
            - 14.2b Advanced Model-Free Control Techniques
            - 14.2c Applications of Advanced Model-Free Control
        - '- Section: 14.3 Advanced Model-Based Control:':
            subsections:
            - 14.3a Introduction to Advanced Model-Based Control
            - 14.3b Advanced Model-Based Control Techniques
            - 14.3c Applications of Advanced Model-Based Control
        - '- Section: 14.4 Advanced Exploration and Exploitation:':
            subsections:
            - 14.4a Introduction to Advanced Exploration and Exploitation
            - 14.4b Balancing Advanced Exploration and Exploitation
            - 14.4c Applications of Advanced Exploration and Exploitation
    - '- Chapter 15: Advanced Applications of Dynamic Programming:':
        sections:
        - '- Section: 15.1 Advanced Optimal Control of Queues:':
            subsections:
            - 15.1a Introduction to Advanced Optimal Control of Queues
            - 15.1b Advanced Optimal Control of Queues Techniques
            - 15.1c Applications of Advanced Optimal Control of Queues
        - '- Section: 15.2 Advanced Inventory Control:':
            subsections:
            - 15.2a Introduction to Advanced Inventory Control
            - 15.2b Advanced Inventory Control Techniques
            - 15.2c Applications of Advanced Inventory Control
        - '- Section: 15.3 Advanced Portfolio Optimization:':
            subsections:
            - 15.3a Introduction to Advanced Portfolio Optimization
            - 15.3b Advanced Portfolio Optimization Techniques
            - 15.3c Applications of Advanced Portfolio Optimization
        - '- Section: 15.4 Advanced Resource Allocation:':
            subsections:
            - 15.4a Introduction to Advanced Resource Allocation
            - 15.4b Advanced Resource Allocation Techniques
            - 15.4c Applications of Advanced Resource Allocation
    - '- Chapter 16: Advanced Routing and Scheduling Problems:':
        sections:
        - '- Section: 16.1 Introduction to Advanced Routing and Scheduling Problems:':
            subsections:
            - 16.1a Definition of Advanced Routing and Scheduling Problems
            - 16.1b Solving Advanced Routing and Scheduling Problems
            - 16.1c Applications of Advanced Routing and Scheduling Problems
        - '- Section: 16.2 Advanced Optimal Stopping Problems:':
            subsections:
            - 16.2a Introduction to Advanced Optimal Stopping Problems
            - 16.2b Solving Advanced Optimal Stopping Problems
            - 16.2c Applications of Advanced Optimal Stopping Problems
        - '- Section: 16.3 Advanced Routing and Scheduling Problems:':
            subsections:
            - 16.3a Introduction to Advanced Routing and Scheduling Problems
            - 16.3b Solving Advanced Routing and Scheduling Problems
            - 16.3c Applications of Advanced Routing and Scheduling Problems
        - '- Section: 16.4 Advanced Optimal Stopping Problems:':
            subsections:
            - 16.4a Introduction to Advanced Optimal Stopping Problems
            - 16.4b Solving Advanced Optimal Stopping Problems
            - 16.4c Applications of Advanced Optimal Stopping Problems
    - '- Chapter 17: Advanced Reinforcement Learning:':
        sections:
        - '- Section: 17.1 Advanced Deep Reinforcement Learning:':
            subsections:
            - 17.1a Introduction to Advanced Deep Reinforcement Learning
            - 17.1b Advanced Deep Reinforcement Learning Techniques
            - 17.1c Applications of Advanced Deep Reinforcement Learning
        - '- Section: 17.2 Advanced Model-Based Reinforcement Learning:':
            subsections:
            - 17.2a Introduction to Advanced Model-Based Reinforcement Learning
            - 17.2b Advanced Model-Based Reinforcement Learning Techniques
            - 17.2c Applications of Advanced Model-Based Reinforcement Learning
        - '- Section: 17.3 Advanced Multi-Agent Reinforcement Learning:':
            subsections:
            - 17.3a Introduction to Advanced Multi-Agent Reinforcement Learning
            - 17.3b Advanced Multi-Agent Reinforcement Learning Techniques
            - 17.3c Applications of Advanced Multi-Agent Reinforcement Learning
        - '- Section: 17.4 Advanced Approximate Dynamic Programming:':
            subsections:
            - 17.4a Introduction to Advanced Approximate Dynamic Programming
            - 17.4b Advanced Approximate Dynamic Programming Techniques
            - 17.4c Applications of Advanced Approximate Dynamic Programming
    - '- Chapter 18: Advanced Optimal Control in Continuous Time:':
        sections:
        - '- Section: 18.1 Advanced Hamilton-Jacobi-Bellman Equation:':
            subsections:
            - 18.1a Introduction to Advanced Hamilton-Jacobi-Bellman Equation
            - 18.1b Solving Advanced Hamilton-Jacobi-Bellman Equation
            - 18.1c Applications of Advanced Hamilton-Jacobi-Bellman Equation
        - '- Section: 18.2 Advanced Pontryagin''s Minimum Principle:':
            subsections:
            - 18.2a Introduction to Advanced Pontryagin's Minimum Principle
            - 18.2b Applying Advanced Pontryagin's Minimum Principle
            - 18.2c Applications of Advanced Pontryagin's Minimum Principle
        - '- Section: 18.3 Advanced Existence and Uniqueness of Optimal Control:':
            subsections:
            - 18.3a Introduction to Advanced Existence and Uniqueness of Optimal Control
            - 18.3b Proving Advanced Existence and Uniqueness of Optimal Control
            - 18.3c Applications of Advanced Existence and Uniqueness of Optimal Control
        - '- Section: 18.4 Advanced Linear Quadratic Regulator in Continuous Time:':
            subsections:
            - 18.4a Introduction to Advanced Linear Quadratic Regulator in Continuous
              Time
            - 18.4b Solving Advanced Linear Quadratic Regulator in Continuous Time
            - 18.4c Applications of
