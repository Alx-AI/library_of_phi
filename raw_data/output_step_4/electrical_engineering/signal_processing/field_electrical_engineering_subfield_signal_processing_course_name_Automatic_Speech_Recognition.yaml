textbook:
  'Automatic Speech Recognition: A Comprehensive Guide":':
    chapters:
    - '- Chapter 1: Course Overview:':
        sections:
        - '- Section: 1.1 Introduction:':
            subsections:
            - 1.1a Overview of Speech Recognition
            - 1.1b History of Speech Recognition
            - 1.1c Applications of Speech Recognition
    - '- Chapter 2: Acoustic Theory of Speech Production:':
        sections:
        - '- Section: 2.1 Speech Production Mechanism:':
            subsections:
            - 2.1a Anatomy of Speech Production
            - 2.1b Phonation Process
            - 2.1c Articulation Process
        - '- Section: 2.2 Vocal Tract Model:':
            subsections:
            - 2.2a Anatomy of Vocal Tract
            - 2.2b Acoustic Properties of Vocal Tract
            - 2.2c Vocal Tract Modelling Techniques
        - '- Section: 2.3 Source-filter Theory:':
            subsections:
            - 2.3a Basics of Source-filter Theory
            - 2.3b Applications in Speech Production
            - 2.3c Limitations of Source-filter Theory
    - '- Chapter 3: Speech Sounds:':
        sections:
        - '- Section: 3.1 Phonetics:':
            subsections:
            - 3.1a Introduction to Phonetics
            - 3.1b Phonetic Transcription
            - 3.1c Phonetic Alphabet
        - '- Section: 3.2 Vowels and Consonants:':
            subsections:
            - 3.2a Classification of Vowels
            - 3.2b Classification of Consonants
            - 3.2c Vowel-Consonant Interactions
        - '- Section: 3.3 Articulatory Phonetics:':
            subsections:
            - 3.3a Basics of Articulatory Phonetics
            - 3.3b Articulatory Features of Speech Sounds
            - 3.3c Articulatory Phonetics in Speech Recognition
        - '- Section: 3.4 Acoustic Phonetics:':
            subsections:
            - 3.4a Introduction to Acoustic Phonetics
            - 3.4b Acoustic Features of Speech Sounds
            - 3.4c Acoustic Phonetics in Speech Recognition
    - '- Chapter 4: Signal Representation:':
        sections:
        - '- Section: 4.1 Time-domain Representation:':
            subsections:
            - 4.1a Basics of Time-domain Representation
            - 4.1b Time-domain Features of Speech Signals
            - 4.1c Time-domain Analysis Techniques
        - '- Section: 4.2 Frequency-domain Representation:':
            subsections:
            - 4.2a Basics of Frequency-domain Representation
            - 4.2b Frequency-domain Features of Speech Signals
            - 4.2c Frequency-domain Analysis Techniques
        - '- Section: 4.3 Fourier Transform:':
            subsections:
            - 4.3a Introduction to Fourier Transform
            - 4.3b Fourier Transform in Speech Signal Analysis
            - 4.3c Limitations and Challenges
        - '- Section: 4.4 Spectrogram:':
            subsections:
            - 4.4a Basics of Spectrogram
            - 4.4b Spectrogram in Speech Signal Analysis
            - 4.4c Spectrogram Interpretation Techniques
    - '- Chapter 5: Vector Quantization:':
        sections:
        - '- Section: 5.1 Codebook Design:':
            subsections:
            - 5.1a Basics of Codebook Design
            - 5.1b Codebook Design Techniques
            - 5.1c Codebook Design in Speech Recognition
        - '- Section: 5.2 Quantization Techniques:':
            subsections:
            - 5.2a Introduction to Quantization
            - 5.2b Quantization Techniques in Speech Recognition
            - 5.2c Quantization Error and Quality
        - '- Section: 5.3 Vector Quantization Algorithms:':
            subsections:
            - 5.3a Basics of Vector Quantization
            - 5.3b Vector Quantization Algorithms
            - 5.3c Vector Quantization in Speech Recognition
    - '- Chapter 6: Pattern Classification:':
        sections:
        - '- Section: 6.1 Introduction to Classification:':
            subsections:
            - 6.1a Basics of Pattern Classification
            - 6.1b Classification Techniques
            - 6.1c Classification in Speech Recognition
        - '- Section: 6.2 Feature Extraction:':
            subsections:
            - 6.2a Basics of Feature Extraction
            - 6.2b Feature Extraction Techniques
            - 6.2c Feature Extraction in Speech Recognition
        - '- Section: 6.3 Classification Algorithms:':
            subsections:
            - 6.3a Introduction to Classification Algorithms
            - 6.3b Classification Algorithms in Speech Recognition
            - 6.3c Evaluation of Classification Algorithms
    - '- Chapter 7: Search:':
        sections:
        - '- Section: 7.1 Language Models:':
            subsections:
            - 7.1a Basics of Language Models
            - 7.1b Language Models in Speech Recognition
            - 7.1c Evaluation of Language Models
        - '- Section: 7.2 Search Algorithms:':
            subsections:
            - 7.2a Introduction to Search Algorithms
            - 7.2b Search Algorithms in Speech Recognition
            - 7.2c Evaluation of Search Algorithms
        - '- Section: 7.3 Beam Search:':
            subsections:
            - 7.3a Basics of Beam Search
            - 7.3b Beam Search in Speech Recognition
            - 7.3c Evaluation of Beam Search
    - '- Chapter 8: Hidden Markov Modeling:':
        sections:
        - '- Section: 8.1 Introduction to HMMs:':
            subsections:
            - 8.1a Basics of Hidden Markov Models
            - 8.1b Hidden Markov Models in Speech Recognition
            - 8.1c Evaluation of Hidden Markov Models
        - '- Section: 8.2 Forward-Backward Algorithm:':
            subsections:
            - 8.2a Basics of Forward-Backward Algorithm
            - 8.2b Forward-Backward Algorithm in HMMs
            - 8.2c Evaluation of Forward-Backward Algorithm
        - '- Section: 8.3 Viterbi Algorithm:':
            subsections:
            - 8.3a Introduction to Viterbi Algorithm
            - 8.3b Viterbi Algorithm in HMMs
            - 8.3c Evaluation of Viterbi Algorithm
        - '- Section: 8.4 Baum-Welch Algorithm:':
            subsections:
            - 8.4a Basics of Baum-Welch Algorithm
            - 8.4b Baum-Welch Algorithm in HMMs
            - 8.4c Evaluation of Baum-Welch Algorithm
    - '- Chapter 9: Acoustic Modeling:':
        sections:
        - '- Section: 9.1 Feature Extraction:':
            subsections:
            - 9.1a Basics of Feature Extraction in Acoustic Modeling
            - 9.1b Feature Extraction Techniques in Acoustic Modeling
            - 9.1c Evaluation of Feature Extraction in Acoustic Modeling
        - '- Section: 9.2 Acoustic Models:':
            subsections:
            - 9.2a Introduction to Acoustic Models
            - 9.2b Acoustic Models in Speech Recognition
            - 9.2c Evaluation of Acoustic Models
        - '- Section: 9.3 Gaussian Mixture Models:':
            subsections:
            - 9.3a Basics of Gaussian Mixture Models
            - 9.3b Gaussian Mixture Models in Acoustic Modeling
            - 9.3c Evaluation of Gaussian Mixture Models
        - '- Section: 9.4 Maximum Likelihood Estimation:':
            subsections:
            - 9.4a Introduction to Maximum Likelihood Estimation
            - 9.4b Maximum Likelihood Estimation in Acoustic Modeling
            - 9.4c Evaluation of Maximum Likelihood Estimation
    - '- Chapter 10: Language Modeling:':
        sections:
        - '- Section: 10.1 N-gram Models:':
            subsections:
            - 10.1a Basics of N-gram Models
            - 10.1b N-gram Models in Language Modeling
            - 10.1c Evaluation of N-gram Models
        - '- Section: 10.2 Statistical Language Models:':
            subsections:
            - 10.2a Introduction to Statistical Language Models
            - 10.2b Statistical Language Models in Language Modeling
            - 10.2c Evaluation of Statistical Language Models
        - '- Section: 10.3 Smoothing Techniques:':
            subsections:
            - 10.3a Basics of Smoothing Techniques
            - 10.3b Smoothing Techniques in Language Modeling
            - 10.3c Evaluation of Smoothing Techniques
    - '- Chapter 11: Graphical Models:':
        sections:
        - '- Section: 11.1 Probabilistic Graphical Models:':
            subsections:
            - 11.1a Introduction to Probabilistic Graphical Models
            - 11.1b Probabilistic Graphical Models in Speech Recognition
            - 11.1c Evaluation of Probabilistic Graphical Models
        - '- Section: 11.2 Markov Random Fields:':
            subsections:
            - 11.2a Basics of Markov Random Fields
            - 11.2b Markov Random Fields in Speech Recognition
            - 11.2c Evaluation of Markov Random Fields
        - '- Section: 11.3 Conditional Random Fields:':
            subsections:
            - 11.3a Introduction to Conditional Random Fields
            - 11.3b Conditional Random Fields in Speech Recognition
            - 11.3c Evaluation of Conditional Random Fields
    - '- Chapter 12: Deep Learning in Speech Recognition:':
        sections:
        - '- Section: 12.1 Introduction to Deep Learning:':
            subsections:
            - 12.1a Basics of Deep Learning
            - 12.1b Deep Learning in Speech Recognition
            - 12.1c Evaluation of Deep Learning Techniques
        - '- Section: 12.2 Neural Networks:':
            subsections:
            - 12.2a Introduction to Neural Networks
            - 12.2b Neural Networks in Speech Recognition
            - 12.2c Evaluation of Neural Networks
        - '- Section: 12.3 Convolutional Neural Networks:':
            subsections:
            - 12.3a Basics of Convolutional Neural Networks
            - 12.3b Convolutional Neural Networks in Speech Recognition
            - 12.3c Evaluation of Convolutional Neural Networks
        - '- Section: 12.4 Recurrent Neural Networks:':
            subsections:
            - 12.4a Introduction to Recurrent Neural Networks
            - 12.4b Recurrent Neural Networks in Speech Recognition
            - 12.4c Evaluation of Recurrent Neural Networks
    - '- Chapter 13: End-to-End Speech Recognition:':
        sections:
        - '- Section: 13.1 Introduction to End-to-End Speech Recognition:':
            subsections:
            - 13.1a Basics of End-to-End Speech Recognition
            - 13.1b End-to-End Speech Recognition Techniques
            - 13.1c Evaluation of End-to-End Speech Recognition
        - '- Section: 13.2 Connectionist Temporal Classification:':
            subsections:
            - 13.2a Introduction to Connectionist Temporal Classification
            - 13.2b Connectionist Temporal Classification in Speech Recognition
            - 13.2c Evaluation of Connectionist Temporal Classification
        - '- Section: 13.3 Sequence-to-Sequence Models:':
            subsections:
            - 13.3a Basics of Sequence-to-Sequence Models
            - 13.3b Sequence-to-Sequence Models in Speech Recognition
            - 13.3c Evaluation of Sequence-to-Sequence Models
        - '- Section: 13.4 Transformer Models:':
            subsections:
            - 13.4a Introduction to Transformer Models
            - 13.4b Transformer Models in Speech Recognition
            - 13.4c Evaluation of Transformer Models
    - '- Chapter 14: Speaker Recognition:':
        sections:
        - '- Section: 14.1 Introduction to Speaker Recognition:':
            subsections:
            - 14.1a Basics of Speaker Recognition
            - 14.1b Speaker Recognition Techniques
            - 14.1c Evaluation of Speaker Recognition
        - '- Section: 14.2 Speaker Verification:':
            subsections:
            - 14.2a Introduction to Speaker Verification
            - 14.2b Speaker Verification Techniques
            - 14.2c Evaluation of Speaker Verification
        - '- Section: 14.3 Speaker Identification:':
            subsections:
            - 14.3a Basics of Speaker Identification
            - 14.3b Speaker Identification Techniques
            - 14.3c Evaluation of Speaker Identification
        - '- Section: 14.4 Speaker Diarization:':
            subsections:
            - 14.4a Introduction to Speaker Diarization
            - 14.4b Speaker Diarization Techniques
            - 14.4c Evaluation of Speaker Diarization
    - '- Chapter 15: Speech Synthesis:':
        sections:
        - '- Section: 15.1 Introduction to Speech Synthesis:':
            subsections:
            - 15.1a Basics of Speech Synthesis
            - 15.1b Speech Synthesis Techniques
            - 15.1c Evaluation of Speech Synthesis
        - '- Section: 15.2 Text-to-Speech Systems:':
            subsections:
            - 15.2a Introduction to Text-to-Speech Systems
            - 15.2b Text-to-Speech Systems Techniques
            - 15.2c Evaluation of Text-to-Speech Systems
        - '- Section: 15.3 Voice Conversion:':
            subsections:
            - 15.3a Basics of Voice Conversion
            - 15.3b Voice Conversion Techniques
            - 15.3c Evaluation of Voice Conversion
        - '- Section: 15.4 Speech-to-Speech Translation:':
            subsections:
            - 15.4a Introduction to Speech-to-Speech Translation
            - 15.4b Speech-to-Speech Translation Techniques
            - 15.4c Evaluation of Speech-to-Speech Translation
    - '- Chapter 16: Multilingual Speech Recognition:':
        sections:
        - '- Section: 16.1 Introduction to Multilingual Speech Recognition:':
            subsections:
            - 16.1a Basics of Multilingual Speech Recognition
            - 16.1b Multilingual Speech Recognition Techniques
            - 16.1c Evaluation of Multilingual Speech Recognition
        - '- Section: 16.2 Cross-lingual Speech Recognition:':
            subsections:
            - 16.2a Introduction to Cross-lingual Speech Recognition
            - 16.2b Cross-lingual Speech Recognition Techniques
            - 16.2c Evaluation of Cross-lingual Speech Recognition
        - '- Section: 16.3 Multilingual Acoustic Models:':
            subsections:
            - 16.3a Basics of Multilingual Acoustic Models
            - 16.3b Multilingual Acoustic Models Techniques
            - 16.3c Evaluation of Multilingual Acoustic Models
        - '- Section: 16.4 Multilingual Language Models:':
            subsections:
            - 16.4a Introduction to Multilingual Language Models
            - 16.4b Multilingual Language Models Techniques
            - 16.4c Evaluation of Multilingual Language Models
    - '- Chapter 17: Speech Recognition in Noisy Environments:':
        sections:
        - '- Section: 17.1 Introduction to Speech Recognition in Noisy Environments:':
            subsections:
            - 17.1a Basics of Speech Recognition in Noisy Environments
            - 17.1b Techniques for Speech Recognition in Noisy Environments
            - 17.1c Evaluation of Speech Recognition in Noisy Environments
        - '- Section: 17.2 Noise Reduction Techniques:':
            subsections:
            - 17.2a Introduction to Noise Reduction Techniques
            - 17.2b Noise Reduction Techniques in Speech Recognition
            - 17.2c Evaluation of Noise Reduction Techniques
        - '- Section: 17.3 Robust Acoustic Models:':
            subsections:
            - 17.3a Basics of Robust Acoustic Models
            - 17.3b Robust Acoustic Models Techniques
            - 17.3c Evaluation of Robust Acoustic Models
        - '- Section: 17.4 Robust Language Models:':
            subsections:
            - 17.4a Introduction to Robust Language Models
            - 17.4b Robust Language Models Techniques
            - 17.4c Evaluation of Robust Language Models
    - '- Chapter 18: Speech Recognition in Real-world Applications:':
        sections:
        - '- Section: 18.1 Introduction to Speech Recognition in Real-world Applications:':
            subsections:
            - 18.1a Basics of Speech Recognition in Real-world Applications
            - 18.1b Techniques for Speech Recognition in Real-world Applications
            - 18.1c Evaluation of Speech Recognition in Real-world Applications
        - '- Section: 18.2 Speech Recognition in Mobile Devices:':
            subsections:
            - 18.2a Introduction to Speech Recognition in Mobile Devices
            - 18.2b Techniques for Speech Recognition in Mobile Devices
            - 18.2c Evaluation of Speech Recognition in Mobile Devices
        - '- Section: 18.3 Speech Recognition in Assistive Technologies:':
            subsections:
            - 18.3a Basics of Speech Recognition in Assistive Technologies
            - 18.3b Techniques for Speech Recognition in Assistive Technologies
            - 18.3c Evaluation of Speech Recognition in Assistive Technologies
        - '- Section: 18.4 Speech Recognition in Smart Homes:':
            subsections:
            - 18.4a Introduction to Speech Recognition in Smart Homes
            - 18.4b Techniques for Speech Recognition in Smart Homes
            - 18.4c Evaluation of Speech Recognition in Smart Homes
    - '- Chapter 19: Evaluation of Speech Recognition Systems:':
        sections:
        - '- Section: 19.1 Introduction to Evaluation of Speech Recognition Systems:':
            subsections:
            - 19.1a Basics of Evaluation of Speech Recognition Systems
            - 19.1b Techniques for Evaluation of Speech Recognition Systems
            - 19.1c Challenges in Evaluation of Speech Recognition Systems
        - '- Section: 19.2 Evaluation Metrics:':
            subsections:
            - 19.2a Introduction to Evaluation Metrics
            - 19.2b Evaluation Metrics in Speech Recognition
            - 19.2c Evaluation of Evaluation Metrics
        - '- Section: 19.3 Evaluation Datasets:':
            subsections:
            - 19.3a Basics of Evaluation Datasets
            - 19.3b Evaluation Datasets in Speech Recognition
            - 19.3c Evaluation of Evaluation Datasets
        - '- Section: 19.4 Evaluation Protocols:':
            subsections:
            - 19.4a Introduction to Evaluation Protocols
            - 19.4b Evaluation Protocols in Speech Recognition
            - 19.4c Evaluation of Evaluation Protocols
    - '- Chapter 20: Future Directions in Speech Recognition:':
        sections:
        - '- Section: 20.1 Introduction to Future Directions in Speech Recognition:':
            subsections:
            - 20.1a Basics of Future Directions in Speech Recognition
            - 20.1b Predicted Future Directions in Speech Recognition
            - 20.1c Evaluation of Predicted Future Directions
        - '- Section: 20.2 Speech Recognition and Artificial Intelligence:':
            subsections:
            - 20.2a Introduction to Speech Recognition and Artificial Intelligence
            - 20.2b Predicted Interactions between Speech Recognition and Artificial
              Intelligence
            - 20.2c Evaluation of Predicted Interactions
        - '- Section: 20.3 Speech Recognition and Big Data:':
            subsections:
            - 20.3a Basics of Speech Recognition and Big Data
            - 20.3b Predicted Interactions between Speech Recognition and Big Data
            - 20.3c Evaluation of Predicted Interactions
        - '- Section: 20.4 Speech Recognition and Privacy:':
            subsections:
            - 20.4a Introduction to Speech Recognition and Privacy
            - 20.4b Predicted Interactions between Speech Recognition and Privacy
            - 20.4c Evaluation of Predicted Interactions
